{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarsonnaila/NLP/blob/main/omkar_lab_assignment3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy8a_jrhlP-O",
        "outputId": "0368c0af-ee24-4629-f138-9fc0d4898cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Students', 'NNS'), ('are', 'VBP'), ('learning', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError\n",
        "sentence = \"Students are learning Natural Language Processing\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Students are learning Natural Language Processing\")\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmonlIsWqJsy",
        "outputId": "8c497376-9660-4672-c6c2-5c16967f6654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Students NOUN\n",
            "are AUX\n",
            "learning VERB\n",
            "Natural PROPN\n",
            "Language PROPN\n",
            "Processing NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying a startup in India.\")\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9mNHFhcqv3Y",
        "outputId": "778f90b4-47cd-45a8-fc8e-3456887346b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple PROPN NNP\n",
            "is AUX VBZ\n",
            "looking VERB VBG\n",
            "at ADP IN\n",
            "buying VERB VBG\n",
            "a DET DT\n",
            "startup NOUN NN\n",
            "in ADP IN\n",
            "India PROPN NNP\n",
            ". PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"Loving the new AI features üòç#AI #MachineLearning\"\n",
        "doc = nlp(text)\n",
        "nouns = []\n",
        "verbs = []\n",
        "for token in doc:\n",
        "  if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
        "    nouns.append(token.text)\n",
        "  elif token.pos_ == \"VERB\":\n",
        "      verbs.append(token.text)\n",
        "      noun_freq = Counter(nouns)\n",
        "      verb_freq = Counter(verbs)\n",
        "\n",
        "      print(\"Noun Frequency:\", noun_freq)\n",
        "      print(\"Verb Frequency:\", verb_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlLAP4tMrB6Y",
        "outputId": "68c52c21-b3a1-48f6-d310-7e6b954b967f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Frequency: Counter()\n",
            "Verb Frequency: Counter({'Loving': 1})\n",
            "Noun Frequency: Counter({'AI': 1})\n",
            "Verb Frequency: Counter({'Loving': 1, 'features': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError\n",
        "sentence = SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO4xlI_3s0Tl",
        "outputId": "1de6b548-7e41-4e58-9460-bc9c238c28a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('SR', 'NNP'), ('University', 'NNP'), ('campus', 'NN'), ('is', 'VBZ'), ('located', 'VBN'), ('in', 'IN'), ('Ananthasagar', 'NNP'), ('village', 'NN'), ('of', 'IN'), ('Hasanparthy', 'NNP'), ('Mandal', 'NNP'), ('in', 'IN'), ('Warangal', 'NNP'), (',', ','), ('Telangana', 'NNP'), (',', ','), ('India', 'NNP'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('in', 'IN'), ('150', 'CD'), ('acres', 'NNS'), (',', ','), ('with', 'IN'), ('both', 'DT'), ('separate', 'JJ'), ('hostel', 'NN'), ('facilities', 'NNS'), ('for', 'IN'), ('boys', 'NNS'), ('and', 'CC'), ('girls', 'NNS'), ('.', '.'), ('There', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('huge', 'JJ'), ('central', 'JJ'), ('library', 'NN'), ('along', 'IN'), ('with', 'IN'), ('Indias', 'NNP'), ('largest', 'JJS'), ('Technology', 'NN'), ('Business', 'NNP'), ('Incubator', 'NNP'), ('(', '('), ('TBI', 'NNP'), (')', ')'), ('in', 'IN'), ('tier', '$'), ('2', 'CD'), ('cities', 'NNS'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(SRUniversity)\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vjc4tsMtDRY",
        "outputId": "0f6b5c0e-1cdc-406f-8253-847b3749a911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET\n",
            "SR PROPN\n",
            "University PROPN\n",
            "campus NOUN\n",
            "is AUX\n",
            "located VERB\n",
            "in ADP\n",
            "Ananthasagar PROPN\n",
            "village NOUN\n",
            "of ADP\n",
            "Hasanparthy PROPN\n",
            "Mandal PROPN\n",
            "in ADP\n",
            "Warangal PROPN\n",
            ", PUNCT\n",
            "Telangana PROPN\n",
            ", PUNCT\n",
            "India PROPN\n",
            ". PUNCT\n",
            "\n",
            " SPACE\n",
            "It PRON\n",
            "is AUX\n",
            "in ADP\n",
            "150 NUM\n",
            "acres NOUN\n",
            ", PUNCT\n",
            "with ADP\n",
            "both DET\n",
            "separate ADJ\n",
            "hostel NOUN\n",
            "facilities NOUN\n",
            "for ADP\n",
            "boys NOUN\n",
            "and CCONJ\n",
            "girls NOUN\n",
            ". PUNCT\n",
            "\n",
            " SPACE\n",
            "There PRON\n",
            "is VERB\n",
            "a DET\n",
            "huge ADJ\n",
            "central ADJ\n",
            "library NOUN\n",
            "along ADP\n",
            "with ADP\n",
            "Indias PROPN\n",
            "largest ADJ\n",
            "Technology PROPN\n",
            "Business PROPN\n",
            "Incubator PROPN\n",
            "( PUNCT\n",
            "TBI PROPN\n",
            ") PUNCT\n",
            "in ADP\n",
            "tier NOUN\n",
            "2 NUM\n",
            "cities NOUN\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "doc = nlp(text)\n",
        "nouns = []\n",
        "verbs = []\n",
        "for token in doc:\n",
        "  if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
        "    nouns.append(token.text)\n",
        "  elif token.pos_ == \"VERB\":\n",
        "      verbs.append(token.text)\n",
        "      noun_freq = Counter(nouns)\n",
        "      verb_freq = Counter(verbs)\n",
        "\n",
        "      print(\"Noun Frequency:\", noun_freq)\n",
        "      print(\"Verb Frequency:\", verb_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0lTySOkuRo_",
        "outputId": "8431ae34-f95f-44a4-c7d4-daa317faf71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Frequency: Counter({'SR': 1, 'University': 1, 'campus': 1})\n",
            "Verb Frequency: Counter({'located': 1})\n",
            "Noun Frequency: Counter({'SR': 1, 'University': 1, 'campus': 1, 'Ananthasagar': 1, 'village': 1, 'Hasanparthy': 1, 'Mandal': 1, 'Warangal': 1, 'Telangana': 1, 'India': 1, 'acres': 1, 'hostel': 1, 'facilities': 1, 'boys': 1, 'girls': 1})\n",
            "Verb Frequency: Counter({'located': 1, 'is': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTuSwZ8bu_r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3rd task"
      ],
      "metadata": {
        "id": "0Gzzr0J6yTwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "157c208e",
        "outputId": "7726aeab-ff6a-464e-8f04-7fdc51d5b7a5"
      },
      "source": [
        "academic_paragraph = \"\"\"The phenomenon of academic vocabulary acquisition is pivotal for tertiary education success. It encompasses specialized terminology, idiomatic expressions, and complex grammatical structures frequently encountered in scholarly discourse. Researchers consistently emphasize that proficiency in this lexicon significantly correlates with comprehension of challenging texts. Furthermore, effective communication within specific disciplines necessitates a deep understanding of these nuanced terms. Students often struggle with the transition from general English to the more formal registers required for academic writing. This challenge is exacerbated by the multifaceted nature of academic words, which often possess multiple meanings or subtle contextual variations. Therefore, pedagogical approaches must explicitly target the development of this essential skill set. Many institutions implement targeted intervention programs to address these deficiencies. These programs typically integrate direct vocabulary instruction with contextualized practice exercises. Moreover, they often leverage digital tools to enhance engagement and facilitate repeated exposure. A common objective is to foster an autonomous learning capacity in students. However, the sheer volume of academic vocabulary presents a considerable hurdle. This necessitates strategic selection of high-frequency and discipline-specific terms for explicit teaching. Consequently, curriculum design must prioritize the integration of vocabulary development across all subject areas. Such an integrated approach ensures sustained exposure and application. Empirical studies demonstrate the efficacy of spaced repetition and active recall techniques in consolidating this knowledge. Additionally, encouraging extensive reading of academic texts is crucial for implicit learning. Ultimately, mastery of academic vocabulary empowers students to articulate sophisticated ideas with precision. This mastery is foundational for critical analysis and original scholarly contributions.\"\"\"\n",
        "print(\"Academic paragraph stored in 'academic_paragraph' variable.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Academic paragraph stored in 'academic_paragraph' variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73d517d9",
        "outputId": "98cd0a0a-2fa5-4f34-ecec-034cd527381a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset') # Download for universal tagset if needed for comparison\n",
        "\n",
        "nltk_tokens = nltk.word_tokenize(academic_paragraph)\n",
        "nltk_pos_tags = nltk.pos_tag(nltk_tokens)\n",
        "print(\"NLTK POS Tags:\")\n",
        "print(nltk_pos_tags[:20]) # Print first 20 tags for brevity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK POS Tags:\n",
            "[('The', 'DT'), ('phenomenon', 'NN'), ('of', 'IN'), ('academic', 'JJ'), ('vocabulary', 'JJ'), ('acquisition', 'NN'), ('is', 'VBZ'), ('pivotal', 'JJ'), ('for', 'IN'), ('tertiary', 'JJ'), ('education', 'NN'), ('success', 'NN'), ('.', '.'), ('It', 'PRP'), ('encompasses', 'VBZ'), ('specialized', 'JJ'), ('terminology', 'NN'), (',', ','), ('idiomatic', 'JJ'), ('expressions', 'NNS')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc44fa0d",
        "outputId": "e077e27d-d3be-45de-ca94-74d9d53774b1"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(academic_paragraph)\n",
        "\n",
        "spacy_pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "print(\"spaCy POS Tags:\")\n",
        "print(spacy_pos_tags[:20]) # Print first 20 tags for brevity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy POS Tags:\n",
            "[('The', 'DET'), ('phenomenon', 'NOUN'), ('of', 'ADP'), ('academic', 'ADJ'), ('vocabulary', 'NOUN'), ('acquisition', 'NOUN'), ('is', 'AUX'), ('pivotal', 'ADJ'), ('for', 'ADP'), ('tertiary', 'ADJ'), ('education', 'NOUN'), ('success', 'NOUN'), ('.', 'PUNCT'), ('It', 'PRON'), ('encompasses', 'VERB'), ('specialized', 'ADJ'), ('terminology', 'NOUN'), (',', 'PUNCT'), ('idiomatic', 'ADJ'), ('expressions', 'NOUN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1de01d90",
        "outputId": "1bdd31a7-2a92-4faf-e778-e76606ab2aef"
      },
      "source": [
        "print(\"Comparison of NLTK and spaCy POS Tags (first 20 tokens):\")\n",
        "print(\"{:<20} {:<10} {:<10}\".format(\"Token\", \"NLTK Tag\", \"spaCy Tag\"))\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Ensure both lists are of comparable length for iteration\n",
        "min_len = min(len(nltk_pos_tags), len(spacy_pos_tags))\n",
        "\n",
        "for i in range(min(min_len, 20)): # Compare first 20 tokens or fewer if paragraph is shorter\n",
        "    nltk_token, nltk_tag = nltk_pos_tags[i]\n",
        "    spacy_token, spacy_tag = spacy_pos_tags[i]\n",
        "    # Ensure tokens match for direct comparison, though tokenization might slightly differ\n",
        "    if nltk_token == spacy_token:\n",
        "        print(f\"{nltk_token:<20} {nltk_tag:<10} {spacy_tag:<10}\")\n",
        "    else:\n",
        "        # If tokenization differs, print both to show the discrepancy\n",
        "        print(f\"NLTK: {nltk_token:<14} {nltk_tag:<10}\\nSpaCy: {spacy_token:<13} {spacy_tag:<10}\")\n",
        "        print(\"-\" * 40)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of NLTK and spaCy POS Tags (first 20 tokens):\n",
            "Token                NLTK Tag   spaCy Tag \n",
            "----------------------------------------\n",
            "The                  DT         DET       \n",
            "phenomenon           NN         NOUN      \n",
            "of                   IN         ADP       \n",
            "academic             JJ         ADJ       \n",
            "vocabulary           JJ         NOUN      \n",
            "acquisition          NN         NOUN      \n",
            "is                   VBZ        AUX       \n",
            "pivotal              JJ         ADJ       \n",
            "for                  IN         ADP       \n",
            "tertiary             JJ         ADJ       \n",
            "education            NN         NOUN      \n",
            "success              NN         NOUN      \n",
            ".                    .          PUNCT     \n",
            "It                   PRP        PRON      \n",
            "encompasses          VBZ        VERB      \n",
            "specialized          JJ         ADJ       \n",
            "terminology          NN         NOUN      \n",
            ",                    ,          PUNCT     \n",
            "idiomatic            JJ         ADJ       \n",
            "expressions          NNS        NOUN      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ed96d9",
        "outputId": "9934084b-666e-492a-9705-f9b62e95275c"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "nouns_spacy = []\n",
        "verbs_spacy = []\n",
        "\n",
        "for token in doc:\n",
        "  if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
        "    nouns_spacy.append(token.text.lower()) # Convert to lowercase for consistent counting\n",
        "  elif token.pos_ == \"VERB\":\n",
        "    verbs_spacy.append(token.text.lower()) # Convert to lowercase for consistent counting\n",
        "\n",
        "noun_freq_spacy = Counter(nouns_spacy)\n",
        "verb_freq_spacy = Counter(verbs_spacy)\n",
        "\n",
        "print(\"SpaCy Noun Frequency (Top 10):\")\n",
        "for noun, count in noun_freq_spacy.most_common(10):\n",
        "    print(f\"  {noun}: {count}\")\n",
        "\n",
        "print(\"\\nSpaCy Verb Frequency (Top 10):\")\n",
        "for verb, count in verb_freq_spacy.most_common(10):\n",
        "    print(f\"  {verb}: {count}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy Noun Frequency (Top 10):\n",
            "  vocabulary: 4\n",
            "  students: 3\n",
            "  texts: 2\n",
            "  terms: 2\n",
            "  development: 2\n",
            "  programs: 2\n",
            "  exposure: 2\n",
            "  learning: 2\n",
            "  mastery: 2\n",
            "  phenomenon: 1\n",
            "\n",
            "SpaCy Verb Frequency (Top 10):\n",
            "  necessitates: 2\n",
            "  encompasses: 1\n",
            "  encountered: 1\n",
            "  emphasize: 1\n",
            "  correlates: 1\n",
            "  struggle: 1\n",
            "  required: 1\n",
            "  exacerbated: 1\n",
            "  possess: 1\n",
            "  target: 1\n"
          ]
        }
      ]
    }
  ]
}