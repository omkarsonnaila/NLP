{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarsonnaila/NLP/blob/main/2403A54108_NLP_Lab_Assignment_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Corpus**"
      ],
      "metadata": {
        "id": "EeRmcKD8EF1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92V30zeS85HE"
      },
      "outputs": [],
      "source": [
        "D1 = \"I am learning Artificial Intelligence\"\n",
        "D2 = \"I am learning Data Science\"\n",
        "D3 = \"I love watching anime\"\n",
        "D4 = \"I love watching movies\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unigram Count**"
      ],
      "metadata": {
        "id": "EsK6XyDvELDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "combined_words = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_words.lower().split()\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "print(\"Unigram Count:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "  print(f\"{word}: {count}\")\n",
        "\n",
        "V = len(unigram_counts)\n",
        "print(f\"\\nSize of the vocabulary = {V}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MPXGzgA-PUl",
        "outputId": "e8411820-300e-4bd7-895e-7f8e22cbeb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Count:\n",
            "i: 4\n",
            "am: 2\n",
            "learning: 2\n",
            "love: 2\n",
            "watching: 2\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "data: 1\n",
            "science: 1\n",
            "anime: 1\n",
            "movies: 1\n",
            "\n",
            "Size of the vocabulary = 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bigram Count**"
      ],
      "metadata": {
        "id": "I4g4yvJYENrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "combined_words = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_words.lower().split()\n",
        "\n",
        "bigrams = []\n",
        "\n",
        "for i in range(len(words) - 1):\n",
        "  bigrams.append((words[i], words[i + 1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "print(\"Bigram Count:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "  print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSYUTHMQATE8",
        "outputId": "df312eb0-1082-41eb-d6ae-089366144cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Count:\n",
            "i am: 2\n",
            "am learning: 2\n",
            "i love: 2\n",
            "love watching: 2\n",
            "learning artificial: 1\n",
            "artificial intelligence: 1\n",
            "intelligence i: 1\n",
            "learning data: 1\n",
            "data science: 1\n",
            "science i: 1\n",
            "watching anime: 1\n",
            "anime i: 1\n",
            "watching movies: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trigram Count**"
      ],
      "metadata": {
        "id": "rpeYj_3KEQX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "combined_words = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_words.lower().split()\n",
        "\n",
        "Trigrams = []\n",
        "\n",
        "for i in range(len(words) - 2):\n",
        "  Trigrams.append((words[i], words[i + 1], words[i + 2]))\n",
        "\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "print(\"Trigram Count:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "  print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IhHQYbWBMZP",
        "outputId": "3abe412a-e52b-46f7-915e-9b4391d1ed3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Count:\n",
            "i am learning: 2\n",
            "i love watching: 2\n",
            "am learning artificial: 1\n",
            "learning artificial intelligence: 1\n",
            "artificial intelligence i: 1\n",
            "intelligence i am: 1\n",
            "am learning data: 1\n",
            "learning data science: 1\n",
            "data science i: 1\n",
            "science i love: 1\n",
            "love watching anime: 1\n",
            "watching anime i: 1\n",
            "anime i love: 1\n",
            "love watching movies: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction using Bigram Count**"
      ],
      "metadata": {
        "id": "0OBhg0AZETCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_probability(word_sequence, bigram_counts, unigram_counts):\n",
        "  words_in_sequence = word_sequence.lower().split()\n",
        "  if not words_in_sequence:\n",
        "    return \"Please provide a word sequence.\"\n",
        "  last_word = words_in_sequence[-1]\n",
        "\n",
        "  potential_next_words = {}\n",
        "  for (w1, w2), count in bigram_counts.items():\n",
        "    if w1 == last_word:\n",
        "      potential_next_words[w2] = count\n",
        "\n",
        "  if not potential_next_words:\n",
        "    return f\"No bigram found starting with '{last_word}\"\n",
        "\n",
        "  last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "  if last_word_unigram_count == 0:\n",
        "    return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "  predicted_word = None\n",
        "  max_probability = -1\n",
        "\n",
        "  for next_word, bigram_count in potential_next_words.items():\n",
        "    probability = bigram_count / last_word_unigram_count\n",
        "    print(f\"Probability of '{next_word}' is {probability}\")\n",
        "    if probability > max_probability:\n",
        "      max_probability = probability\n",
        "      predicted_word = next_word\n",
        "\n",
        "  return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = bigram_probability(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I love watching\"\n",
        "next_word2 = bigram_probability(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"anime I\"\n",
        "next_word3 = bigram_probability(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"something\"\n",
        "next_word4 = bigram_probability(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KGR_E-4FAds",
        "outputId": "04c04811-7475-42f2-8343-5cdad9635307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of 'learning' is 1.0\n",
            "Given sequence: 'I am', predicted next word: 'learning'\n",
            "Probability of 'anime' is 0.5\n",
            "Probability of 'movies' is 0.5\n",
            "Given sequence: 'I love watching', predicted next word: 'anime'\n",
            "Probability of 'am' is 0.5\n",
            "Probability of 'love' is 0.5\n",
            "Given sequence: 'anime I', predicted next word: 'am'\n",
            "Given sequence: 'something', predicted next word: 'No bigram found starting with 'something'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Bigram Model**"
      ],
      "metadata": {
        "id": "onwJzoCTEb7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter some text: \")\n",
        "next_word1 = bigram_probability(text, bigram_counts, unigram_counts)\n",
        "\n",
        "print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viqpNwxZIcG6",
        "outputId": "75346518-b849-48cb-8a37-54e4fa295fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter some text: I am\n",
            "Probability of 'learning' is 1.0\n",
            "Given sequence: 'I am', predicted next word: 'learning'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction using Trigram Count**"
      ],
      "metadata": {
        "id": "G3P3xGLFEgUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigram_counts, bigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigram_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am learning\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I love watching\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKnw8s5oAmV5",
        "outputId": "157aeefc-a0b3-4fd5-9f6c-22db0912c3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  artificial is  0.5\n",
            "probability of  data is  0.5\n",
            "Given sequence: 'I am learning', predicted next word: 'artificial'\n",
            "probability of  anime is  0.5\n",
            "probability of  movies is  0.5\n",
            "Given sequence: 'I love watching', predicted next word: 'anime'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Trigram Model**"
      ],
      "metadata": {
        "id": "R4PrEFgIEkpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text =input(\"Enter some text: \")\n",
        "next_word1 = predict_next_word_trigram(text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tij0A6UvCaWo",
        "outputId": "90dc44dc-aa44-4739-ffe9-85931540f785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter some text: I am\n",
            "probability of  learning is  1.0\n",
            "Given sequence: 'I am', predicted next word: 'learning'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction using Bigram Count with Laplace Smoothing**"
      ],
      "metadata": {
        "id": "8Rj2cAHVEn8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I love watching\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"anime I\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"something\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrdAPwS-CkbM",
        "outputId": "cab37d58-b4cb-42a2-b9ab-9117a154d527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of learning is  0.23076923076923078\n",
            "Given sequence: 'I am', predicted next word: 'learning'\n",
            "probability of anime is  0.15384615384615385\n",
            "probability of movies is  0.15384615384615385\n",
            "Given sequence: 'I love watching', predicted next word: 'anime'\n",
            "probability of am is  0.2\n",
            "probability of love is  0.2\n",
            "Given sequence: 'anime I', predicted next word: 'am'\n",
            "Given sequence: 'something', predicted next word: 'No bigram found starting with 'something'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothing based Bigram Model**"
      ],
      "metadata": {
        "id": "f_zHEvFcExKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter some text: \")\n",
        "next_word1 = predict_next_word_bigram_Laplace(text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-9YxmQDCy_6",
        "outputId": "b8477e2b-17d6-4c36-a4ca-6c712ae5b962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter some text: I am\n",
            "probability of learning is  0.23076923076923078\n",
            "Given sequence: 'I am', predicted next word: 'learning'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction using Trigram Count with Laplace Smoothing**"
      ],
      "metadata": {
        "id": "_QTyMVW6E2RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am learning\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I love watching\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "377IuzE2C7Zw",
        "outputId": "bbd3a181-6450-4cb9-f244-0b06f4d3f85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  artificial is  0.15384615384615385\n",
            "probability of  data is  0.15384615384615385\n",
            "Given sequence: 'I am learning', predicted next word: 'artificial'\n",
            "probability of  anime is  0.15384615384615385\n",
            "probability of  movies is  0.15384615384615385\n",
            "Given sequence: 'I love watching', predicted next word: 'anime'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothing based Trigram Model**"
      ],
      "metadata": {
        "id": "Ug7ZOyeiE_3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter some text: \")\n",
        "next_word1 = predict_next_word_trigram_Laplace(text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkAFUnyeDGP0",
        "outputId": "a45a6b76-65af-4bb3-f5a6-464cb343ee21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter some text: I am learning\n",
            "probability of  artificial is  0.15384615384615385\n",
            "probability of  data is  0.15384615384615385\n",
            "Given sequence: 'I am learning', predicted next word: 'artificial'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction using Bigram Count with Add-K Smoothing**"
      ],
      "metadata": {
        "id": "wf72ykUcFIYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I love watching\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"anime I\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"something\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVjwNtP4DNdk",
        "outputId": "f0d02615-f84e-445b-a09e-9d80ce26289b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of learning is  0.3333333333333333\n",
            "Given sequence: 'I am', predicted next word: 'learning'\n",
            "probability of anime is  0.2\n",
            "probability of movies is  0.2\n",
            "Given sequence: 'I love watching', predicted next word: 'anime'\n",
            "probability of am is  0.2631578947368421\n",
            "probability of love is  0.2631578947368421\n",
            "Given sequence: 'anime I', predicted next word: 'am'\n",
            "Given sequence: 'something', predicted next word: 'No bigram found starting with 'something'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothing based Bigram Model**"
      ],
      "metadata": {
        "id": "Hj8xm_JXFSJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter some text: \")\n",
        "next_word1 = predict_next_word_bigram_K(text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JcZOyXRDZSY",
        "outputId": "124ff8ed-8db6-458b-c488-b40add4a2fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter some text: I love\n",
            "probability of watching is  0.3333333333333333\n",
            "Given sequence: 'I love', predicted next word: 'watching'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction using Trigram Count with Add-K Smoothing**"
      ],
      "metadata": {
        "id": "YLpUlYgnFYEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am learning\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I love watching\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKaxNe8cDqRF",
        "outputId": "242bf078-4457-4d45-b965-9e98b5ca6b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  artificial is  0.2\n",
            "probability of  data is  0.2\n",
            "Given sequence: 'I am learning', predicted next word: 'artificial'\n",
            "probability of  anime is  0.2\n",
            "probability of  movies is  0.2\n",
            "Given sequence: 'I love watching', predicted next word: 'anime'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothing based Trigram Model**"
      ],
      "metadata": {
        "id": "dt3kZqwmFefu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter some text: \")\n",
        "next_word1 = predict_next_word_trigram_K(text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxVqwNucD4Ss",
        "outputId": "66567ffc-2095-4258-fde1-d544cf6028d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter some text: I love\n",
            "probability of  watching is  0.3333333333333333\n",
            "Given sequence: 'I love', predicted next word: 'watching'\n"
          ]
        }
      ]
    }
  ]
}